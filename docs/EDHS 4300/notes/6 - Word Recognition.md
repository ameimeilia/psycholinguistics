---
layout: default
title: Word Recognition
parent: Notes
nav_order: 6
---
# Word Recognition

## Listening
- 150 words/minute
- sounds have to be correctly identified
- word boundaries have to be accurately located
- a string of sounds has to be mapped onto the correct word
- you cannot perceive faster than the speaker speaks

process:
1. try to identify the word as the acoustic signal progresses
2. narrow down until you find a word
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-22 at 5.51.58 PM.png' | relative_url}}" alt="Screenshot" width="400">
</div>

## Reading
- 200-400 words/minute
- a jumble of arbitrary symbols have to be mapped onto words
- the arbitrary symbols have some relationship with sounds
- the system is a culturally developed arbitrary code

process:
1. scanning the visual word features
2. compare with words in lexicon
3. make a decision: is what I see similar enough to what I have in my lexicon?
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-22 at 5.53.16 PM.png' | relative_url}}" alt="Screenshot" width="400">
</div>

## Timing and Word Access
- time serves as one of the most important methodological tools for studying how language processing works
- used to compare how long people take to process words

## Word Organization
- it seems that words aren’t organized in our minds independently of one another, but rather, are **connected together in complex webs**
- words are interconnected → once a lexical item is activated, other “related” words are also activated
- words are organized as “neighborhoods” which can be sparsely or densely populated
- dense neighborhoods have many competitors for words and vice versa for sparse neighborhoods
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-22 at 6.08.37 PM.png' | relative_url}}" alt="Screenshot" width="400">
</div>

## Reaction Time and Other Measures
- **naming task**: participants are visually presented with a word or object that they have to name; the time it takes a participant to start to pronounce the word aloud is measured
- **lexical decision task**: participants must decide whether a string of letters is a word or nonword
- **tachistoscopic identification**: participants are shown words for very short times; thresholds at which participants can no longer confidently identify items are recorded (subliminal perception)

## Priming
- how a stimulus you just experienced will affect how you respond to a later stimulus
- this is true of any stimuli: pictures, smells, non-linguistic sounds, etc
- when you encounter a stimulus of a given type, you activate its mental representation, but as you search for the representation, **you activate associates** of that stimulus
- priming is the residual activation from the previously experienced stimuli
- **semantic/associative priming**: meaning relationship between the prime and target word (ex. beer, wine)
- **form priming**: the prime and the target are not related semantically, but are related in their phonological form (ex. beer, deer)
- **masked priming**: the prime word is presented so quickly that it is not consciously processed, but will result in the priming effect
- **repetition priming**: once you have identified a word, it becomes easier to identify it the next time

## Semantic Conflict
- **Stroop test**: interference in the reaction time of the naming and recognition task (ex. “yellow” written in the color blue)

**Speed of response in lexical decision tasks**
- people respond quickly to impossible words like TLAT, SNER, and MROCK
- this is because they are impossible combinations in English
- it takes longer for possible non-words such as SKERN, PLIM, and FLOOP
- people also respond fastest to familiar words like BANK and CLOCK

## Recap
- lexical items are stored in networks
- activating a word will facilitate other words in the same network
- priming is a technique used in the study of word recognition
- when a word is primed, lexical access is facilitated
- when a word is selected, competitors get inhibited

## Frequent Words
- Zipf’s law: a word frequency is inversely related to its position in the frequency ranking
- the most frequent word is twice as frequent as the second
- the most frequent word is three times as frequent as the the third
- …
- general rule: frequent words are recognized faster
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-24 at 5.53.44 PM.png' | relative_url}}" alt="Screenshot" width="500">
</div>

## Polysemous Words
- words have multiplicity of meanings
- words are only useful with context
- context helps with word recognition: bottom up/top down
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-24 at 5.59.38 PM.png' | relative_url}}" alt="Screenshot">
</div>
- when initially hearing a word, all meanings are activated, then wrong meanings are deactivated

## Perceiving Speech
- the hearer must take the speech signal and identify what the original phonetic elements were
- this is complicated because the speech signal is:
	- **continuous**: there are no spaces between consonants and vowels, or even between words
	- transmits information in **parallel**: the speech signal contains information about phonetic segments because of co-articulation; properties of each phoneme persist throughout the word
	- is highly **variable**: variability among speakers (anatomy), variability within speakers (people change the way they speak), co-articulation (phoneme is affected by surrounding phonemes), ambient noise (other noises happening simultaneously); cocktail party effect

## Cohort Model of Lexical Access
- accounts for many facts about lexical retrieval and helps summarize a number of facts related to lexical access
- **acoustic information** is rapidly transformed into **phonological information** and lexical entries that match the stimulus phonologically are activated
- after the first syllable of a word is received, all lexical entries in its cohort are activated, after the second syllable is received, a subset of those will remain activated…
- finally, you reach the **recognition point**
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-24 at 6.07.41 PM.png' | relative_url}}" alt="Screenshot">
</div>

**Eye-tracking Experiment by Allopenna**
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-24 at 6.08.15 PM.png' | relative_url}}" alt="Screenshot">
</div>
- bilingual eye-tracking experiment conducted by Spivey and Marian, revealed cross-minguistic cohort-effect

**Eye-tracking Experiment - Rhyme Effect**
<div style="text-align: center;">
  <img src="{{ '/images/Screenshot 2024-10-24 at 6.11.22 PM.png' | relative_url}}" alt="Screenshot" width="350">
</div>

## The Motor Theory of Speech Perception
- Liberman, Cooper, et al.
- perception of speech is linked to an internal motor recognitino
- the theory has gained new interest since the discovery of mirror neurons

## Multimodality of Speech Perception
- speech perception is not only an auditory activity, it is also a visual activity
- **The McGurk effect**: auditory component of one sound + visual component of another sound = perception of third sound

## Phonemic Restoration
- people hear words from which a phoneme has been removed/masked through noise - they are not able to detect the gap
- another example to show that speech perception is an active process

## Ganong Effect
- the identity of a word can affect the perception of the individual sounds within a word

## Perceiving Speech
- during lexical retrieval, the system locates words on as much acoustic info that is available
- afterwards, the word is checked against the acoustic signal (**post-access matching**)
- once the word is matched, the full phonological representation becomes the percept
- **slips of the ear** occur when there is background noise or when the hearer is distracted (slips of the ear as “heard” in songs, are called **Mondegreens**)

## Ventriloquism: Example of Perceptual Illusion
- tendency by listeners to localize the sound where the moving mouth is, either the speaker or the puppet
- based on the fact that acoustic effects are produced in many ways
- based on the “active” role of the listener

## Bottom-Up vs. Top-Down
- **bottom-up**: when details of the acoustic signal help you build a phonoogical representation
- **top-down**: information that is not part of the acoustic signal (context) helps you build a phonological representation